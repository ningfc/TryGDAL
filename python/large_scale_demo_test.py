#!/usr/bin/env python3
"""
å¤§è§„æ¨¡çº¿è¦ç´ æ€§èƒ½æµ‹è¯• - æ¼”ç¤ºç‰ˆæœ¬
é€‚åˆå½“å‰macOSç¯å¢ƒçš„å°è§„æ¨¡æµ‹è¯•æ¼”ç¤º
"""

import os
import sys
import time
import random
import math
import platform
import psutil
import gc
from osgeo import gdal, ogr, osr

# æ˜ç¡®å¯ç”¨å¼‚å¸¸å¤„ç†
gdal.UseExceptions()
ogr.UseExceptions()
osr.UseExceptions()

class PerformanceTestDemo:
    """æ€§èƒ½æµ‹è¯•æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.output_dir = "/Users/fangchaoning/Code/gdal/TryGDAL/python/test_output/demo_test"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        # æ¼”ç¤ºç‰ˆæœ¬çš„æµ‹è¯•å¤§å°ï¼ˆé€‚åˆmacOSå¼€å‘ç¯å¢ƒï¼‰
        self.test_sizes = [10000, 20000, 30000]  # 1ä¸‡ã€2ä¸‡ã€3ä¸‡è¦ç´ 
        self.points_per_line = 100
        self.test_formats = ['Shapefile', 'GeoPackage']
        
        print("å¤§è§„æ¨¡çº¿è¦ç´ æ€§èƒ½æµ‹è¯• - æ¼”ç¤ºç‰ˆæœ¬")
        print("=" * 60)
        print(f"å½“å‰å¹³å°: {platform.system()} {platform.machine()}")
        print(f"å†…å­˜: {psutil.virtual_memory().total / (1024**3):.1f} GB")
        print(f"ç£ç›˜ç©ºé—´: {psutil.disk_usage(os.path.expanduser('~')).free / (1024**3):.1f} GB")
        print(f"GDALç‰ˆæœ¬: {gdal.VersionInfo('RELEASE_NAME')}")
        print("-" * 60)
    
    def generate_complex_linestring(self, line_id, points_count=100):
        """ç”Ÿæˆå¤æ‚çš„çº¿è¦ç´ """
        # åŸºäºåŒ—äº¬å¸‚èŒƒå›´ç”Ÿæˆ
        base_lon = 116.0 + (line_id % 1000) * 0.001
        base_lat = 39.4 + (line_id % 1000) * 0.001
        
        line = ogr.Geometry(ogr.wkbLineString)
        
        current_lon = base_lon
        current_lat = base_lat
        
        for i in range(points_count):
            if i == 0:
                line.AddPoint(current_lon, current_lat)
            else:
                angle_change = random.uniform(-math.pi/6, math.pi/6)
                distance = random.uniform(0.0005, 0.002)
                
                current_lon += distance * math.cos(angle_change)
                current_lat += distance * math.sin(angle_change)
                
                current_lon = max(116.0, min(117.0, current_lon))
                current_lat = max(39.4, min(40.6, current_lat))
                
                line.AddPoint(current_lon, current_lat)
        
        # ç”Ÿæˆå±æ€§
        road_types = ['é«˜é€Ÿå…¬è·¯', 'ä¸»å¹²é“', 'æ¬¡å¹²é“', 'æ”¯è·¯']
        attributes = {
            'road_id': line_id,
            'name': f'Road_{line_id}',
            'road_type': random.choice(road_types),
            'width': round(random.uniform(3.0, 50.0), 1),
            'max_speed': random.choice([30, 40, 50, 60, 80, 100, 120]),
            'length_km': round(line.Length() * 111.0, 3),
            'lanes': random.randint(1, 8)
        }
        
        return line, attributes
    
    def test_performance(self):
        """æ‰§è¡Œæ€§èƒ½æµ‹è¯•"""
        print("å¼€å§‹æ¼”ç¤ºæµ‹è¯•...")
        
        all_results = {}
        
        for size in self.test_sizes:
            print(f"\n{'='*50}")
            print(f"æµ‹è¯•æ•°æ®é‡: {size:,} ä¸ªçº¿è¦ç´ ")
            print("="*50)
            
            # æ£€æŸ¥èµ„æº
            estimated_memory = size * 1024 * 2
            available_memory = psutil.virtual_memory().available
            
            if available_memory < estimated_memory:
                print(f"âš ï¸  å†…å­˜å¯èƒ½ä¸è¶³ï¼Œä½†ç»§ç»­æµ‹è¯•...")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            print(f"ç”Ÿæˆ {size:,} ä¸ªçº¿è¦ç´ ...")
            start_time = time.perf_counter()
            
            test_data = []
            for i in range(size):
                line, attributes = self.generate_complex_linestring(i, self.points_per_line)
                test_data.append((line, attributes))
                
                if (i + 1) % 5000 == 0:
                    print(f"  è¿›åº¦: {i+1:,}/{size:,}")
            
            data_gen_time = time.perf_counter() - start_time
            print(f"æ•°æ®ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {data_gen_time:.2f}ç§’")
            
            # æµ‹è¯•å„ç§æ ¼å¼
            size_results = {}
            for format_name in self.test_formats:
                print(f"\næµ‹è¯• {format_name} æ ¼å¼...")
                
                try:
                    result = self.test_format_performance(format_name, test_data, size)
                    size_results[format_name] = result
                    self.print_result(format_name, result)
                    
                except Exception as e:
                    print(f"  âŒ {format_name} æµ‹è¯•å¤±è´¥: {e}")
                    size_results[format_name] = None
            
            all_results[size] = {
                'data_generation_time': data_gen_time,
                'formats': size_results
            }
            
            # æ¸…ç†å†…å­˜
            del test_data
            gc.collect()
            
            # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨
            memory_usage = psutil.virtual_memory()
            print(f"\nå½“å‰å†…å­˜ä½¿ç”¨: {memory_usage.percent:.1f}% ({memory_usage.used/(1024**3):.1f}GB)")
        
        # ç”Ÿæˆå¯¹æ¯”åˆ†æ
        self.analyze_results(all_results)
        
        return all_results
    
    def test_format_performance(self, format_name, test_data, size):
        """æµ‹è¯•æ ¼å¼æ€§èƒ½"""
        srs = osr.SpatialReference()
        srs.ImportFromEPSG(4326)
        
        if format_name == 'Shapefile':
            file_path = os.path.join(self.output_dir, f"lines_{size}.shp")
        else:
            file_path = os.path.join(self.output_dir, f"lines_{size}.gpkg")
        
        results = {}
        
        # å†™å…¥æµ‹è¯•
        start_memory = psutil.virtual_memory().used
        start_time = time.perf_counter()
        
        success = self.write_format(format_name, file_path, test_data, srs)
        
        write_time = time.perf_counter() - start_time
        end_memory = psutil.virtual_memory().used
        
        if not success:
            return {'error': 'Write failed'}
        
        file_size = self.get_file_size(format_name, file_path)
        
        results['write_time'] = write_time
        results['file_size'] = file_size
        results['write_throughput'] = len(test_data) / write_time
        results['memory_used'] = end_memory - start_memory
        
        # è¯»å–æµ‹è¯•
        start_time = time.perf_counter()
        feature_count = self.read_file(file_path)
        read_time = time.perf_counter() - start_time
        
        results['read_time'] = read_time
        results['read_throughput'] = feature_count / read_time if read_time > 0 else 0
        results['feature_count'] = feature_count
        
        # ç©ºé—´æŸ¥è¯¢æµ‹è¯•
        start_time = time.perf_counter()
        query_count = self.test_spatial_query(file_path)
        query_time = time.perf_counter() - start_time
        
        results['query_time'] = query_time
        results['query_count'] = query_count
        
        return results
    
    def write_format(self, format_name, file_path, test_data, srs):
        """å†™å…¥æ ¼å¼"""
        try:
            # æ¸…ç†æ—§æ–‡ä»¶
            if format_name == 'Shapefile':
                base_name = os.path.splitext(file_path)[0]
                for ext in ['.shp', '.shx', '.dbf', '.prj']:
                    related_file = base_name + ext
                    if os.path.exists(related_file):
                        os.remove(related_file)
                driver = ogr.GetDriverByName("ESRI Shapefile")
            else:
                if os.path.exists(file_path):
                    os.remove(file_path)
                driver = ogr.GetDriverByName("GPKG")
            
            datasource = driver.CreateDataSource(file_path)
            layer = datasource.CreateLayer("roads", srs, ogr.wkbLineString)
            
            # åˆ›å»ºå­—æ®µ
            fields = [
                ("road_id", ogr.OFTInteger),
                ("name", ogr.OFTString),
                ("road_type", ogr.OFTString),
                ("width", ogr.OFTReal),
                ("max_speed", ogr.OFTInteger),
                ("length_km", ogr.OFTReal),
                ("lanes", ogr.OFTInteger)
            ]
            
            for field_name, field_type in fields:
                field_defn = ogr.FieldDefn(field_name, field_type)
                if field_type == ogr.OFTString:
                    field_defn.SetWidth(50)
                layer.CreateField(field_defn)
            
            # æ‰¹é‡å†™å…¥
            layer.StartTransaction()
            
            for i, (geom, attributes) in enumerate(test_data):
                feature = ogr.Feature(layer.GetLayerDefn())
                
                for field_name, value in attributes.items():
                    if layer.GetLayerDefn().GetFieldIndex(field_name) >= 0:
                        feature.SetField(field_name, value)
                
                feature.SetGeometry(geom)
                layer.CreateFeature(feature)
                feature = None
                
                # æ¯1000æ¡æäº¤ä¸€æ¬¡äº‹åŠ¡
                if (i + 1) % 1000 == 0:
                    layer.CommitTransaction()
                    layer.StartTransaction()
            
            layer.CommitTransaction()
            datasource = None
            return True
            
        except Exception as e:
            print(f"    å†™å…¥å¤±è´¥: {e}")
            return False
    
    def read_file(self, file_path):
        """è¯»å–æ–‡ä»¶"""
        if not os.path.exists(file_path):
            return 0
        
        datasource = ogr.Open(file_path, 0)
        if not datasource:
            return 0
        
        layer = datasource.GetLayer(0)
        if not layer:
            return 0
        
        count = 0
        for feature in layer:
            # æ¨¡æ‹Ÿå®é™…ä½¿ç”¨
            _ = feature.GetField("name")
            geom = feature.GetGeometryRef()
            if geom:
                _ = geom.Length()
            count += 1
        
        datasource = None
        return count
    
    def test_spatial_query(self, file_path):
        """ç©ºé—´æŸ¥è¯¢æµ‹è¯•"""
        if not os.path.exists(file_path):
            return 0
        
        datasource = ogr.Open(file_path, 0)
        if not datasource:
            return 0
        
        layer = datasource.GetLayer(0)
        if not layer:
            return 0
        
        # åˆ›å»ºæŸ¥è¯¢åŒºåŸŸ
        query_geom = ogr.Geometry(ogr.wkbPolygon)
        ring = ogr.Geometry(ogr.wkbLinearRing)
        ring.AddPoint(116.3, 39.8)
        ring.AddPoint(116.5, 39.8)
        ring.AddPoint(116.5, 40.0)
        ring.AddPoint(116.3, 40.0)
        ring.AddPoint(116.3, 39.8)
        query_geom.AddGeometry(ring)
        
        layer.SetSpatialFilter(query_geom)
        count = layer.GetFeatureCount()
        layer.SetSpatialFilter(None)
        
        datasource = None
        return count
    
    def get_file_size(self, format_name, file_path):
        """è·å–æ–‡ä»¶å¤§å°"""
        if format_name == 'Shapefile':
            base_name = os.path.splitext(file_path)[0]
            total_size = 0
            for ext in ['.shp', '.shx', '.dbf', '.prj']:
                related_file = base_name + ext
                if os.path.exists(related_file):
                    total_size += os.path.getsize(related_file)
            return total_size
        else:
            return os.path.getsize(file_path) if os.path.exists(file_path) else 0
    
    def format_size(self, size_bytes):
        """æ ¼å¼åŒ–å¤§å°"""
        if size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
    
    def print_result(self, format_name, result):
        """æ‰“å°ç»“æœ"""
        if 'error' in result:
            print(f"  âŒ {format_name} å¤±è´¥")
            return
        
        print(f"  âœ… {format_name} ç»“æœ:")
        print(f"    å†™å…¥: {result['write_time']:.2f}s ({result['write_throughput']:.0f} è¦ç´ /s)")
        print(f"    æ–‡ä»¶: {self.format_size(result['file_size'])}")
        print(f"    è¯»å–: {result['read_time']:.2f}s ({result['read_throughput']:.0f} è¦ç´ /s)")
        print(f"    æŸ¥è¯¢: {result['query_time']:.3f}s (æ‰¾åˆ° {result['query_count']} è¦ç´ )")
        print(f"    å†…å­˜: {self.format_size(result['memory_used'])}")
    
    def analyze_results(self, all_results):
        """åˆ†æç»“æœ"""
        print(f"\n" + "="*60)
        print("æ€§èƒ½åˆ†ææ€»ç»“")
        print("="*60)
        
        print(f"\næ•°æ®é‡ç¼©æ”¾åˆ†æ:")
        for size in self.test_sizes:
            if size in all_results and 'formats' in all_results[size]:
                formats = all_results[size]['formats']
                print(f"\n{size:,} è¦ç´ :")
                
                for format_name in self.test_formats:
                    if format_name in formats and formats[format_name]:
                        result = formats[format_name]
                        if 'error' not in result:
                            throughput = result['write_throughput']
                            file_size_mb = result['file_size'] / (1024 * 1024)
                            print(f"  {format_name:12}: {throughput:6.0f} è¦ç´ /s, {file_size_mb:5.1f} MB")
        
        print(f"\né¢„æµ‹100ä¸‡è¦ç´ æ€§èƒ½:")
        # åŸºäºæµ‹è¯•ç»“æœé¢„æµ‹
        if len(all_results) >= 2:
            sizes = sorted(all_results.keys())
            for format_name in self.test_formats:
                results_list = []
                for size in sizes:
                    if (size in all_results and 
                        'formats' in all_results[size] and 
                        format_name in all_results[size]['formats'] and
                        all_results[size]['formats'][format_name] and
                        'error' not in all_results[size]['formats'][format_name]):
                        
                        result = all_results[size]['formats'][format_name]
                        results_list.append((size, result))
                
                if len(results_list) >= 2:
                    # ç®€å•çº¿æ€§é¢„æµ‹
                    avg_throughput = sum(r[1]['write_throughput'] for r in results_list) / len(results_list)
                    avg_size_per_feature = sum(r[1]['file_size'] / r[0] for r in results_list) / len(results_list)
                    
                    estimated_time = 1000000 / avg_throughput
                    estimated_size = (1000000 * avg_size_per_feature) / (1024 * 1024 * 1024)
                    
                    print(f"  {format_name:12}: é¢„è®¡ {estimated_time/60:.1f} åˆ†é’Ÿ, ~{estimated_size:.1f} GB")
        
        print(f"\nå»ºè®®:")
        print(f"  âœ“ å½“å‰macOSç¯å¢ƒé€‚åˆ3ä¸‡è¦ç´ ä»¥ä¸‹çš„æµ‹è¯•")
        print(f"  âš ï¸ ç™¾ä¸‡è¦ç´ æµ‹è¯•éœ€è¦LinuxæœåŠ¡å™¨ç¯å¢ƒ")
        print(f"  âš ï¸ å»ºè®®ä½¿ç”¨åˆ†æ‰¹å¤„ç†ç­–ç•¥å¤„ç†å¤§æ•°æ®")
        print(f"  âš ï¸ å»ºè®®ä½¿ç”¨æµå¼å¤„ç†å‡å°‘å†…å­˜ä½¿ç”¨")

def offer_cleanup(output_dir):
    """è¯¢é—®ç”¨æˆ·æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®"""
    print(f"\n" + "="*50)
    print("æ•°æ®æ¸…ç†é€‰é¡¹")
    print("="*50)
    
    if not os.path.exists(output_dir):
        print("ğŸ“ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
        return
    
    # ç»Ÿè®¡æµ‹è¯•æ–‡ä»¶
    test_files = []
    total_size = 0
    
    for file in os.listdir(output_dir):
        file_path = os.path.join(output_dir, file)
        if os.path.isfile(file_path) and (file.endswith(('.shp', '.gpkg')) or 
                                         file.endswith(('.shx', '.dbf', '.prj'))):
            test_files.append(file_path)
            total_size += os.path.getsize(file_path)
    
    if not test_files:
        print("ğŸ“ æ²¡æœ‰å‘ç°æµ‹è¯•æ•°æ®æ–‡ä»¶ï¼Œæ— éœ€æ¸…ç†")
        return
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®ç»Ÿè®¡:")
    print(f"  æµ‹è¯•æ–‡ä»¶æ•°é‡: {len(test_files)} ä¸ª")
    print(f"  å ç”¨ç£ç›˜ç©ºé—´: {format_size(total_size)}")
    print(f"  å­˜å‚¨ä½ç½®: {output_dir}")
    
    print(f"\nğŸ“ æ–‡ä»¶åˆ—è¡¨:")
    for file_path in sorted(test_files):
        file_name = os.path.basename(file_path)
        size = os.path.getsize(file_path)
        print(f"  ğŸ“„ {file_name:25} {format_size(size):>10}")
    
    try:
        choice = input(f"\næ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®? [y/N]: ").strip().lower()
        
        if choice == 'y':
            deleted_count = 0
            deleted_size = 0
            
            for file_path in test_files:
                try:
                    size = os.path.getsize(file_path)
                    os.remove(file_path)
                    deleted_count += 1
                    deleted_size += size
                    print(f"  âœ… å·²åˆ é™¤: {os.path.basename(file_path)}")
                except Exception as e:
                    print(f"  âŒ åˆ é™¤å¤±è´¥: {os.path.basename(file_path)} - {e}")
            
            print(f"\nğŸ“Š æ¸…ç†ç»“æœ:")
            print(f"  åˆ é™¤æ–‡ä»¶æ•°é‡: {deleted_count} ä¸ª")
            print(f"  é‡Šæ”¾ç£ç›˜ç©ºé—´: {format_size(deleted_size)}")
        else:
            print("âœ… ä¿ç•™æµ‹è¯•æ•°æ®")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  æ¸…ç†æ“ä½œè¢«å–æ¶ˆ")

def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"

def main():
    """ä¸»å‡½æ•°"""
    print("âš ï¸  è¿™æ˜¯å¤§è§„æ¨¡æµ‹è¯•çš„æ¼”ç¤ºç‰ˆæœ¬")
    print("é€‚åˆåœ¨macOSå¼€å‘ç¯å¢ƒä¸­éªŒè¯æ¦‚å¿µå’Œæ–¹æ³•")
    print("å®é™…çš„ç™¾ä¸‡è¦ç´ æµ‹è¯•å»ºè®®åœ¨LinuxæœåŠ¡å™¨ä¸Šè¿›è¡Œ\n")
    
    try:
        demo = PerformanceTestDemo()
        results = demo.test_performance()
        print(f"\nâœ… æ¼”ç¤ºæµ‹è¯•å®Œæˆ!")
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†æ•°æ®
        offer_cleanup(demo.output_dir)
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  æµ‹è¯•è¢«ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()